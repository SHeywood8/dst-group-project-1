{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb734ab-c1b4-4620-8eae-296138c7cab2",
   "metadata": {},
   "source": [
    "# Attempts At Improvement\n",
    "\n",
    "In this document we attempt a few methods at improving the performance of the Logistic Regression model.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Dealing With Missing Data](#Dealing-With-Missing-Data)\n",
    "2. [Tuning the Parameters of the Model](#Tuning-the-Parameters-of-the-Model)\n",
    "3. [Conclusion](#Conclusion)\n",
    "4. [References](#References)\n",
    "\n",
    "We first get our data back into an analysable state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86769836-b3c7-42cc-b5f5-1e83515a01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt # This can be used to install the necessary modules if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf58d8a4-838f-4975-8529-caef0f6400a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5ed0b5-1d52-4e63-a3d0-3fbc19e00fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/X_train.csv\", index_col=0)  # Use the first column as index\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\", index_col=0)  # Use the first column as index\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\", index_col=0)    # Use the first column as index\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\", index_col=0)    # Use the first column as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e72da5-d3e9-4296-8579-e9093029dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat({'X_train':X_train, 'X_test':X_test})\n",
    "objects = ['workclass','education','marital-status','occupation','relationship','race','sex','native-country']\n",
    "keys = [0]*len(objects)\n",
    "\n",
    "for i in range(len(objects)):\n",
    "    X_all[objects[i]], keys[i] = pd.factorize(X_all[objects[i]])\n",
    "\n",
    "X_train = X_all.loc['X_train']\n",
    "X_test = X_all.loc['X_test']\n",
    "\n",
    "y_all = pd.concat({'y_train':y_train, 'y_test':y_test})\n",
    "y_all['income'], income_key = pd.factorize(y_all['income'])\n",
    "\n",
    "y_train = y_all.loc['y_train']\n",
    "y_test = y_all.loc['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31a191bf-73d8-4e7d-9703-befa839ec263",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), linear_model.LogisticRegression())\n",
    "\n",
    "pipe.fit(X_train, y_train.values.ravel())\n",
    "y_pred2 = pipe.predict(X_test)\n",
    "\n",
    "trainscore = pipe.score(X_train, y_train)\n",
    "testscore = pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132f036-1d90-41be-9970-761b82cc989c",
   "metadata": {},
   "source": [
    "# Dealing With Missing Data\n",
    "\n",
    "Another thing that may be affecting our model is the missing data. Our data only contains missing entries in the training data and none in the testing data. This is good since we wont be surprised with missing values when testing, but also bad since these missing values could be affecting the efficiency of the model. We will test a couple different methods, namely removing the rows with missing data, or methods of imputing the missing data.\n",
    "\n",
    "First we check to see where the missing data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e2b7f21-97ef-4171-b954-7974ea952401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         2799\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        2809\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     857\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2 = pd.read_csv(\"../data/X_train.csv\", index_col=0) # Reimport dataset so we have it in it's original state\n",
    "X_train2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417ad14-7429-4af3-a7d2-3ef03afac2be",
   "metadata": {},
   "source": [
    "There are 3 columns with missing data, namely 'workclass', 'occupation', and 'native-country'. These are all originally object features, and so during our factorising, the NaN values would have been converted to '-1', which we can see below. This could cause problems for our data, especially when we scaled it as the mean and variance will be skewed by these values, and so this motivates us to investigate how fixing this problem will impact our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bbdc5f1-745f-4cf9-8b1f-653253f4f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4 -1  5  6  7]\n"
     ]
    }
   ],
   "source": [
    "print(X_train['workclass'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf569108-6bec-4507-99d5-17eb1111fa45",
   "metadata": {},
   "source": [
    "One easy way to deal with the data is to simply **remove the rows with missing values**. This can be dangerous for smaller datasets but since for our group the number of rows with missing data is around 10%, this could be a valid way to deal with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be051da-7ed6-4c99-8a23-b0911fc47478",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingcols = ['workclass','occupation','native-country'] # collect missing columns\n",
    "X_train_nan = X_train.copy() # We no longer want to alter the original dataframe so we make a copy for our tests\n",
    "\n",
    "# convert the missing values from -1 back to nan, so that we can then use the .dropna method\n",
    "for col in missingcols:\n",
    "    X_train_nan.loc[X_train[col] == -1,col] = np.nan\n",
    "\n",
    "X_y_All = pd.concat({'X_train':X_train_nan,'y_train':y_train},axis=1)\n",
    "X_y_All = X_y_All.dropna()\n",
    "\n",
    "X_train2 = X_y_All.loc[:,'X_train']\n",
    "y_train2 = X_y_All.loc[:,'y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b97e2950-8f37-4583-b754-df665b087184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score with removed rows: 0.8268466837632624\n",
      "The training score without removed rows: 0.8258912857645698\n",
      "\n",
      "The test score with removed rows: 0.8198059108954565\n",
      "The test score without removed rows: 0.8201367445963829\n"
     ]
    }
   ],
   "source": [
    "pipe_rem = make_pipeline(StandardScaler(), linear_model.LogisticRegression())\n",
    "pipe_rem.fit(X_train2, y_train2.values.ravel())\n",
    "\n",
    "y_pred_rem = pipe_rem.predict(X_test)\n",
    "\n",
    "trainscore_rem = pipe_rem.score(X_train, y_train) # Using the model trained on the removed rows back on the dataset with missing values\n",
    "testscore_rem = pipe_rem.score(X_test, y_test)\n",
    "print(f'The training score with removed rows: {trainscore_rem}')\n",
    "print(f'The training score without removed rows: {trainscore}\\n')\n",
    "print(f'The test score with removed rows: {testscore_rem}')\n",
    "print(f'The test score without removed rows: {testscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0ee36-3b86-478b-a2a4-f36578343dda",
   "metadata": {},
   "source": [
    "We see that removing the rows has infact increased our training score but decreased the testing score, we can't conclude much from this and will continue to investigate imputing before comparing all of the methods at the end.\n",
    "\n",
    "We will now investigate a few different methods of **imputing**, namely mean, mode, and median imputation. Imputing is the act of filling in missing data by predicting what the data could be based on the other data. Mean, mode, and median imputing are 3 very simple methods of doing this, and whilst there are more complex methods available, such as Multiple Imputation, but that is too complex for this simple digression. We will investigate now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0931c754-a2c7-4008-9f80-ac52eb7c0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean = X_train_nan.copy()\n",
    "X_train_mode = X_train_nan.copy()\n",
    "X_train_medi = X_train_nan.copy()\n",
    "\n",
    "for col in missingcols:\n",
    "    col_mean = X_train_nan[col].mean()\n",
    "    col_mode = (X_train_nan[col].mode())[0]\n",
    "    col_medi = X_train_nan[col].median()\n",
    "    X_train_mean.fillna({col: col_mean}, inplace=True)\n",
    "    X_train_mode.fillna({col: col_mode}, inplace=True)\n",
    "    X_train_medi.fillna({col: col_medi}, inplace=True)\n",
    "\n",
    "pipe_mean = make_pipeline(StandardScaler(), linear_model.LogisticRegression())\n",
    "pipe_mode = make_pipeline(StandardScaler(), linear_model.LogisticRegression())\n",
    "pipe_medi = make_pipeline(StandardScaler(), linear_model.LogisticRegression())\n",
    "\n",
    "pipe_mean.fit(X_train, y_train.values.ravel())\n",
    "pipe_mode.fit(X_train, y_train.values.ravel())\n",
    "pipe_medi.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred_mean = pipe_mean.predict(X_test)\n",
    "y_pred_mode = pipe_mode.predict(X_test)\n",
    "y_pred_medi = pipe_medi.predict(X_test)\n",
    "\n",
    "trainscore_mean = pipe_mean.score(X_train_mean,y_train)\n",
    "trainscore_mode = pipe_mode.score(X_train_mode,y_train)\n",
    "trainscore_medi = pipe_medi.score(X_train_medi,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06fc54bb-9aa3-40aa-be91-e1ced4870b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Model Score          = 0.8258912857645698\n",
      "Removed rows Model Score    = 0.8268466837632624\n",
      "Mean Imputing Model Score   = 0.8254638708704178\n",
      "Mode Imputing Model Score   = 0.8254638708704178\n",
      "Median Imputing Model Score = 0.8255141549756122\n"
     ]
    }
   ],
   "source": [
    "print(f'Normal Model Score          = {trainscore}')\n",
    "print(f'Removed rows Model Score    = {trainscore_rem}')\n",
    "print(f'Mean Imputing Model Score   = {trainscore_mean}')\n",
    "print(f'Mode Imputing Model Score   = {trainscore_mode}')\n",
    "print(f'Median Imputing Model Score = {trainscore_medi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe074f4f-741c-4064-b5b5-19f88a5afa49",
   "metadata": {},
   "source": [
    "We see that the training scores for all of these imputing methods are worse than both the normal model, and the model where we removed the rows. This suggests to us that the missing data did not play a strong part in our model, which is reinforced by the fact that the mean and mode imputing end up giving us the same score. In our normal model, in a sense we were encoding the missing data as it's own category, this is because the method we used to encode the rows encodes `NaN` data as `-1`, and so it is treated as it's own category. From our EDA in document `02.1`, we saw that the majority of the missing data came from individuals earning less than 50k a year, and so treating this as it's own category may infact assist our model in identifying the cases for less than 50k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11c524-09d7-43c7-8cac-41958e7347a2",
   "metadata": {},
   "source": [
    "# Tuning the Parameters of the Model\n",
    "\n",
    "The LogisticRegression function in sklearn has a parameter known simply as `C`, set to `C = 1` by default. This parameter represents the inverse of the regularisation strength, where smaller values represent stronger regularisation. In our case, the training and testing scores are fairly similar and so we don't need to worry about potential overfitting, but we may have some underfitting. A good way to tune parameters in models is through a process known as cross-validation, which leaves out sections of the training data to be used to test the models and compare the values of the parameters. Scikit-Learn has a built in model to do this, known as LogisticRegressionCV, which we will implement here... TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bd32e-95f5-4c1d-be57-418b5f96e876",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Thus, in conclusion we have that this model does not seem to be easily improvable, and our initial score was quite good for the limitations of the model. Reasons for this and more indepth consideration can be found in the next document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6e502-ac0b-49ae-a072-bb044ce575fc",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80035f8d-0db9-4ab4-a3e4-3c220d110041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
